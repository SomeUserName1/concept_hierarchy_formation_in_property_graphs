25th July 14:00
Give That Thing A Name: Label/Property/Concept Hierarchy Inference

Overall Structure: 

1. General:
    - [ ] Make code modular and functional to execute different varieties of the pipeline

2. Data: Yelp and Synthetic 
    - [x] Make callable from python
    - [x] Create Tree from whats generated
    â» [ ] and hand-crafted one for Yelp data set

3. Preprocessing: Binary Count Vectorization, SVD/PCA/ICA or tSNE/UMAP/MDS. 
    - [x] Binary count vectorization
    - [x] PCA-tSNE combination for data vis. and numeric only methods. 

4. Clustering:
    1. Pre-Clustering: (sklearn, pyclustering)
        - [x] Use pipeline and Grid search for hyper param tuning
        - [x] SkLearn: AffinityProp, Spectral, Optics, DBScan
        - [ ] PyClustering: KMeans, KMedoid, KMedians, EM, BSAS, MBSAS, TTSAS
        - [ ] Wrappers for PyClustering to use Pipeline and GridSearchCV from sklearn
    2. Hierarcical Clustering
        - [ ] Single, Average, Complete, Ward, Robust Single, maybe divisive
    3. End-to-End Approaches
        - [ ] HDBScan (hdbscan package)
        - [ ] Conceptual Clustering (concept_formation package)

5. Evaluation:
        - [ ] (Optional: First Phase: Shilouette Coef., Adjusted Rand Index, MI based scores, V-meassure, FMI, CHI, DBI)
        - [ ] Second Phase: Tree Edit Distance & KFold Cross Validation
            Cross validation:
            Take 90% dataset & create hierachy
            take 10% dataset & validate hierarchy
            - [ ] get TED running with appropriate costs via python
            - [ ] convert Dendrogram to .tree file
        - [ ] Visualization
            
6. Questions that Project should answer:
    1. Find label hierarchies
    2. Extract only robust sub-hierarchies (rates of convergence for tree clusters)
    3. How distant are two instances
    4. Deal with noise
    5. How can we make such an existing algorithm graph aware: By considering the structure of a graph (in the clustering) regain deleted labels
        - for each node how many edges of each type: Introduce new properties with graphy traits
        - Neighbours, types of neighbours, type of relationships, cumulative relationship, 
    6. How much do we need to sample to get a correct hierarchy?
 
Project: Ignore the graph
Belivable results of how good the results are ignoring the graph structure
Thesis: reintroduce graph structure => algos more robust


______

NEXT WEEK:
ALL Code, as many presentation as possible
23.07:
Presentation slides finished
MAX 1 MIN LONGER: better 1 min earlier


Find methods to introduce noise in data set
1. Baseline
2. Take random node, remove random label



Cost vs accuracy per algo 
Algos   | Runtime   | Accuracy  | ...   |
__________________________

TODO
0. Find methods to destroy hierarchy: Found only complex graph and genetic algo. based version
1. TED running
2. port data: call jar for py
2. Fix algos: restructure code
3. Bench Pure algo runtime (memory): find propper way to do so
4. Try SCD/tSNE/... and bench runtime-accuracy trade off

how it supports our scenario, why/why not


Presentation:
1. Introduction
    1. Motivation: Yelp, got hierarchy of some struct, dont wanna extract by hand (ex.); In Neo4J: vehicle => car, vehicle =>bus, bus, car; need to explicitly state. But concetually there is an hioerarchy, just not explitly in the data. Cant do iut by hand so => hierarchical clustering 
    2.  Probelm definition (formal, proper terminology)
2. Solution
    1. Related Work: Algorithms, Brief how they work; include examples and weioght by how well they work
3. Evaluation
    1. Setup
        1. synthetic baseline: generation, noise intro, ground truth, measures: runtime and accuracy (ted)
        2. 1 Slide on the pipeline
    2. Results: if time also for yelp, but only if propperly
        1 Base experiment
            1. Table
            2. Graphs
        2. Noise exp 1
        3. NOise exp n
    preliminary yelp experiment for transition
        
4. Conclusions and What do we want to acheive:
    - multiple hioerarchies: either relationship or disjoint
    - hierarcical info on labels (selectivity)
    => HOW: Take structural info, neibhbourhood to infer hierarcy from noisy data again
    
    doesnt need to be exact but should make sense
